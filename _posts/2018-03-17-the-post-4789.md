---
title: SfMLearner学习
layout: post
tags: []
category: Uncategoried
---
## Approach

从无标签的视频序列中训练一个深度估计CNN和相机姿态估计CNN。虽然是一起训练的，但是得到的深度的模型和姿态的模型能够在测试时独立运行。

#### 综合视图监督
深度和姿态预测CNNs的核心的监督信息来源自novel view synthesis：给定场景的一个视图，合成一个相机在另一个不同姿态下的新图像。我们通过合成目标视图的深度图、这个时刻的pose和附近视角下的图像。而这个合成的步骤能通过CNNs的全可微操作实现。
令$$<I_1,I_2,...,I_N>$$作为待训练图像序列的输入，其中$$I_t$$是目标视图，其他的图像序列为源视图$$I_s(1\le s\le N,s\ne t)$$。那么视图生成目标函数能通过下式表示：

$$\mathcal{L_{vs}}=\sum_s\sum_p|I_t(p_)-\hat{I}_s(p)|$$

其中$$p$$表示像素坐标，$$\hat{I}_{s}$$表示源视图$$I_s$$根据深度图像渲染模型（具体见下一小结）warped到目标坐标下的视图。这个模型以预测到的深度$$\hat{D}_t$$,预测的4*4的相机变换矩阵$$\hat{T}_t \to s$$和源视图的$$I_s$$作为输入。

这篇文章与其他方法相比是预先不需要pose的信息。同时能够将预测的pose作为学习框架的部分输入。

#### 可微深度图像渲染
#### 建模模型限制
#### 克服梯度的局部性
#### 网络结构